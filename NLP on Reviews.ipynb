{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply NLP to PRS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PRS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378491, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>auth_id</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>prs_qboa_raw</th>\n",
       "      <th>prs_qboa_segment</th>\n",
       "      <th>prs_qboa_score</th>\n",
       "      <th>prs_qboa_voice</th>\n",
       "      <th>prs_qbo_raw</th>\n",
       "      <th>prs_qbo_segment</th>\n",
       "      <th>prs_qbo_score</th>\n",
       "      <th>...</th>\n",
       "      <th>qboa_company_name</th>\n",
       "      <th>qboa_channel</th>\n",
       "      <th>qboa_signup_date</th>\n",
       "      <th>country</th>\n",
       "      <th>company_tenure</th>\n",
       "      <th>wholesale_flag</th>\n",
       "      <th>proadvisor_flag</th>\n",
       "      <th>proadvisor_tier</th>\n",
       "      <th>qbo_certification_flag</th>\n",
       "      <th>qbse_attached_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1325779545</td>\n",
       "      <td>127088051</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>This new platform sucks. I am unable to manage...</td>\n",
       "      <td>0</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>TaxWorks Plus, Inc</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>United States</td>\n",
       "      <td>3 Months or Less</td>\n",
       "      <td>Wholesale</td>\n",
       "      <td>ProAdvisor</td>\n",
       "      <td>ELITE</td>\n",
       "      <td>Not Certified</td>\n",
       "      <td>QBSE Not Attached</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1345924720</td>\n",
       "      <td>1346476015</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>2</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>still too many glitches</td>\n",
       "      <td>2</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>Claire Prescott</td>\n",
       "      <td>Client Invite</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>United States</td>\n",
       "      <td>3 Months or Less</td>\n",
       "      <td>Not Wholesale</td>\n",
       "      <td>ProAdvisor</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>Not Certified</td>\n",
       "      <td>QBSE Not Attached</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1310633145</td>\n",
       "      <td>300822642</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>5</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>jjjjjjjjjjjjjjjjjjjjjjj</td>\n",
       "      <td>4</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>Hamilton, Stuebi &amp; Young, LLC</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>United States</td>\n",
       "      <td>4 - 12 Months</td>\n",
       "      <td>Not Wholesale</td>\n",
       "      <td>Not ProAdvisor</td>\n",
       "      <td>Not ProAdvisor</td>\n",
       "      <td>Not Certified</td>\n",
       "      <td>QBSE Not Attached</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1310925660</td>\n",
       "      <td>1291056130</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>10</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>1</td>\n",
       "      <td>works so well</td>\n",
       "      <td>10</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Damon Felix Fanucchi</td>\n",
       "      <td>Client Invite</td>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>United States</td>\n",
       "      <td>4 - 12 Months</td>\n",
       "      <td>Not Wholesale</td>\n",
       "      <td>ProAdvisor</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>Not Certified</td>\n",
       "      <td>QBSE Not Attached</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1219923465</td>\n",
       "      <td>181802120</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>It is slow, difficult to use, challenging to f...</td>\n",
       "      <td>0</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>donnaharris@simplifymybooks.com's company</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2014-06-03</td>\n",
       "      <td>United States</td>\n",
       "      <td>4 - 12 Months</td>\n",
       "      <td>Not Wholesale</td>\n",
       "      <td>Not ProAdvisor</td>\n",
       "      <td>Not ProAdvisor</td>\n",
       "      <td>Not Certified</td>\n",
       "      <td>QBSE Not Attached</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_id     auth_id survey_date  prs_qboa_raw prs_qboa_segment  \\\n",
       "0  1325779545   127088051  2015-04-01             0        Detractor   \n",
       "1  1345924720  1346476015  2015-04-01             2        Detractor   \n",
       "2  1310633145   300822642  2015-04-01             5        Detractor   \n",
       "3  1310925660  1291056130  2015-04-01            10         Promoter   \n",
       "4  1219923465   181802120  2015-04-01             0        Detractor   \n",
       "\n",
       "   prs_qboa_score                                     prs_qboa_voice  \\\n",
       "0              -1  This new platform sucks. I am unable to manage...   \n",
       "1              -1                            still too many glitches   \n",
       "2              -1                            jjjjjjjjjjjjjjjjjjjjjjj   \n",
       "3               1                                      works so well   \n",
       "4              -1  It is slow, difficult to use, challenging to f...   \n",
       "\n",
       "   prs_qbo_raw prs_qbo_segment  prs_qbo_score  ...  \\\n",
       "0            0       Detractor             -1  ...   \n",
       "1            2       Detractor             -1  ...   \n",
       "2            4       Detractor             -1  ...   \n",
       "3           10        Promoter              1  ...   \n",
       "4            0       Detractor             -1  ...   \n",
       "\n",
       "                           qboa_company_name   qboa_channel qboa_signup_date  \\\n",
       "0                         TaxWorks Plus, Inc        Unknown       2015-01-09   \n",
       "1                            Claire Prescott  Client Invite       2015-02-10   \n",
       "2              Hamilton, Stuebi & Young, LLC        Unknown       2014-12-05   \n",
       "3                       Damon Felix Fanucchi  Client Invite       2014-12-09   \n",
       "4  donnaharris@simplifymybooks.com's company        Unknown       2014-06-03   \n",
       "\n",
       "         country    company_tenure wholesale_flag proadvisor_flag  \\\n",
       "0  United States  3 Months or Less      Wholesale      ProAdvisor   \n",
       "1  United States  3 Months or Less  Not Wholesale      ProAdvisor   \n",
       "2  United States     4 - 12 Months  Not Wholesale  Not ProAdvisor   \n",
       "3  United States     4 - 12 Months  Not Wholesale      ProAdvisor   \n",
       "4  United States     4 - 12 Months  Not Wholesale  Not ProAdvisor   \n",
       "\n",
       "  proadvisor_tier qbo_certification_flag qbse_attached_flag  \n",
       "0           ELITE          Not Certified  QBSE Not Attached  \n",
       "1          SILVER          Not Certified  QBSE Not Attached  \n",
       "2  Not ProAdvisor          Not Certified  QBSE Not Attached  \n",
       "3          SILVER          Not Certified  QBSE Not Attached  \n",
       "4  Not ProAdvisor          Not Certified  QBSE Not Attached  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('prs_qboa_survey_data.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>auth_id</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>prs_qboa_raw</th>\n",
       "      <th>prs_qboa_segment</th>\n",
       "      <th>prs_qboa_score</th>\n",
       "      <th>prs_qboa_voice</th>\n",
       "      <th>prs_qbo_raw</th>\n",
       "      <th>prs_qbo_segment</th>\n",
       "      <th>prs_qbo_score</th>\n",
       "      <th>...</th>\n",
       "      <th>qboa_company_name</th>\n",
       "      <th>qboa_channel</th>\n",
       "      <th>qboa_signup_date</th>\n",
       "      <th>country</th>\n",
       "      <th>company_tenure</th>\n",
       "      <th>wholesale_flag</th>\n",
       "      <th>proadvisor_flag</th>\n",
       "      <th>proadvisor_tier</th>\n",
       "      <th>qbo_certification_flag</th>\n",
       "      <th>qbse_attached_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>378486</th>\n",
       "      <td>404573131</td>\n",
       "      <td>569506960</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>pamlim.ea@gmail.com's company-QB Accountant</td>\n",
       "      <td>Migrated</td>\n",
       "      <td>2013-12-10</td>\n",
       "      <td>United States</td>\n",
       "      <td>12 Months or More</td>\n",
       "      <td>Wholesale</td>\n",
       "      <td>ProAdvisor</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>Not Certified</td>\n",
       "      <td>QBSE Not Attached</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378487</th>\n",
       "      <td>123146092739979</td>\n",
       "      <td>193514820994419</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>10</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>Passive</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Davis &amp; Snead, CPAs</td>\n",
       "      <td>Client Invite</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>United States</td>\n",
       "      <td>4 - 12 Months</td>\n",
       "      <td>Not Wholesale</td>\n",
       "      <td>ProAdvisor</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>Certified</td>\n",
       "      <td>QBSE Not Attached</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378488</th>\n",
       "      <td>123145799964739</td>\n",
       "      <td>123145800920584</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>8</td>\n",
       "      <td>Passive</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Client Invite</td>\n",
       "      <td>2017-04-09</td>\n",
       "      <td>United States</td>\n",
       "      <td>12 Months or More</td>\n",
       "      <td>Not Wholesale</td>\n",
       "      <td>ProAdvisor</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>Not Certified</td>\n",
       "      <td>QBSE Not Attached</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378489</th>\n",
       "      <td>571270615</td>\n",
       "      <td>111089839</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>0</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>karol@morerafinance.com's Company</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>United States</td>\n",
       "      <td>12 Months or More</td>\n",
       "      <td>Wholesale</td>\n",
       "      <td>ProAdvisor</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>Not Certified</td>\n",
       "      <td>QBSE Not Attached</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378490</th>\n",
       "      <td>1297070835</td>\n",
       "      <td>193514332782902</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>10</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Accounting Gurus, LLC</td>\n",
       "      <td>Client Invite</td>\n",
       "      <td>2014-10-29</td>\n",
       "      <td>United States</td>\n",
       "      <td>12 Months or More</td>\n",
       "      <td>Wholesale</td>\n",
       "      <td>ProAdvisor</td>\n",
       "      <td>ELITE</td>\n",
       "      <td>Not Certified</td>\n",
       "      <td>QBSE Attached</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             company_id          auth_id survey_date  prs_qboa_raw  \\\n",
       "378486        404573131        569506960  2019-08-10             5   \n",
       "378487  123146092739979  193514820994419  2019-08-10            10   \n",
       "378488  123145799964739  123145800920584  2019-08-10             8   \n",
       "378489        571270615        111089839  2019-08-10             0   \n",
       "378490       1297070835  193514332782902  2019-08-10            10   \n",
       "\n",
       "       prs_qboa_segment  prs_qboa_score prs_qboa_voice  prs_qbo_raw  \\\n",
       "378486        Detractor              -1            NaN            6   \n",
       "378487         Promoter               1            NaN            7   \n",
       "378488          Passive               0            NaN            9   \n",
       "378489        Detractor              -1            NaN            9   \n",
       "378490         Promoter               1            NaN           10   \n",
       "\n",
       "       prs_qbo_segment  prs_qbo_score  ...  \\\n",
       "378486       Detractor             -1  ...   \n",
       "378487         Passive              0  ...   \n",
       "378488        Promoter              1  ...   \n",
       "378489        Promoter              1  ...   \n",
       "378490        Promoter              1  ...   \n",
       "\n",
       "                                  qboa_company_name   qboa_channel  \\\n",
       "378486  pamlim.ea@gmail.com's company-QB Accountant       Migrated   \n",
       "378487                          Davis & Snead, CPAs  Client Invite   \n",
       "378488                                          NaN  Client Invite   \n",
       "378489            karol@morerafinance.com's Company        Unknown   \n",
       "378490                        Accounting Gurus, LLC  Client Invite   \n",
       "\n",
       "       qboa_signup_date        country     company_tenure wholesale_flag  \\\n",
       "378486       2013-12-10  United States  12 Months or More      Wholesale   \n",
       "378487       2018-08-21  United States      4 - 12 Months  Not Wholesale   \n",
       "378488       2017-04-09  United States  12 Months or More  Not Wholesale   \n",
       "378489       2013-01-11  United States  12 Months or More      Wholesale   \n",
       "378490       2014-10-29  United States  12 Months or More      Wholesale   \n",
       "\n",
       "       proadvisor_flag proadvisor_tier qbo_certification_flag  \\\n",
       "378486      ProAdvisor            GOLD          Not Certified   \n",
       "378487      ProAdvisor            GOLD              Certified   \n",
       "378488      ProAdvisor          SILVER          Not Certified   \n",
       "378489      ProAdvisor        PLATINUM          Not Certified   \n",
       "378490      ProAdvisor           ELITE          Not Certified   \n",
       "\n",
       "       qbse_attached_flag  \n",
       "378486  QBSE Not Attached  \n",
       "378487  QBSE Not Attached  \n",
       "378488  QBSE Not Attached  \n",
       "378489  QBSE Not Attached  \n",
       "378490      QBSE Attached  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "\n",
    "Data processing involves the following steps:\n",
    "\n",
    "1. Remove empty texts\n",
    "2. Extract relevant columns (text reviews, ratings)\n",
    "3. Convert 11 classes into two classes (positive = 1 and negative = 0)\n",
    "4. Convert words to lower case\n",
    "5. Remove stop words\n",
    "6. Remove punctuation from texts\n",
    "7. Stemming or Lemmatization\n",
    "\n",
    "Note the missing data in the reviews.\n",
    "\n",
    "Extract reviews and ratings, remove records with empty strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows:  154429\n",
      "Sample reviews:\n",
      " 0    This new platform sucks. I am unable to manage...\n",
      "1                              still too many glitches\n",
      "2                              jjjjjjjjjjjjjjjjjjjjjjj\n",
      "3                                        works so well\n",
      "4    It is slow, difficult to use, challenging to f...\n",
      "Name: prs_qboa_voice, dtype: object\n",
      "\n",
      "Corresponding ratings:\n",
      " 0     0\n",
      "1     2\n",
      "2     5\n",
      "3    10\n",
      "4     0\n",
      "Name: prs_qboa_raw, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data=data[~data['prs_qboa_voice'].isnull()]\n",
    "text=data['prs_qboa_voice']\n",
    "rating=data['prs_qboa_raw']\n",
    "print('Remaining rows: ',text.shape[0])\n",
    "print(\"Sample reviews:\\n\",text.head())\n",
    "print(\"\\nCorresponding ratings:\\n\",rating[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplify Ratings to 0 (for 0-7) or 1 (for 8-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    86229\n",
       "0    68200\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = [int(rate>7) for rate in rating]\n",
    "print(ratings[:5])\n",
    "pd.DataFrame(ratings)[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to determine how many unique words in corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text_list):\n",
    "    cv = CountVectorizer(binary=True)\n",
    "    cv.fit(text_list)\n",
    "    X = cv.transform(text_list)\n",
    "    return(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words:  26953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    This new platform sucks. I am unable to manage...\n",
       "1                              still too many glitches\n",
       "2                              jjjjjjjjjjjjjjjjjjjjjjj\n",
       "3                                        works so well\n",
       "4    It is slow, difficult to use, challenging to f...\n",
       "Name: prs_qboa_voice, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of unique words: ',count_words(text))\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 stop words:\n",
      " ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "\n",
      "Reviews with no stop words:\n",
      " 0    new platform sucks. unable manage clients look...\n",
      "1                                  still many glitches\n",
      "2                              jjjjjjjjjjjjjjjjjjjjjjj\n",
      "3                                           works well\n",
      "4    slow, difficult use, challenging figure accomp...\n",
      "Name: prs_qboa_voice, dtype: object\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english') # Set checking is faster in Python than list.\n",
    "print(len(stop),'stop words:\\n', stop)\n",
    "\n",
    "# List comprehension.\n",
    "text_nosw = text.apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop)]))\n",
    "\n",
    "#print('\\nNumber of unique words: ',count_words(text_nosw))\n",
    "print('\\nReviews with no stop words:\\n',text_nosw[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function (and call it) to remove punctuation and convert to all lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_WITH_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\<)|(\\>)\")\n",
    "REPLACE_NO_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)|(\\_)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words:  28224\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new platform sucks  unable manage clients look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>still many glitches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jjjjjjjjjjjjjjjjjjjjjjj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slow  difficult use  challenging figure accomp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  new platform sucks  unable manage clients look...\n",
       "1                                still many glitches\n",
       "2                            jjjjjjjjjjjjjjjjjjjjjjj\n",
       "3                                         works well\n",
       "4  slow  difficult use  challenging figure accomp..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clean = pd.DataFrame(preprocess_reviews(text_nosw),columns=['text'])\n",
    "print('Number of unique words: ',count_words(text_clean['text']))\n",
    "text_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This new platform sucks. I am unable to manage my clients and look like a fool in from my client that I tried to convert to in 2015 with the 9.99 promotion.  I am unable to access and support did nothing for me.\n",
      "printing reports&#x2F;no window available&#x2F;cant save to local computer\n"
     ]
    }
   ],
   "source": [
    "print(text[0])\n",
    "print(text[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new platform sucks  unable manage clients look like fool client tried convert 2015 9 99 promotion  unable access support nothing me \n",
      "printing reports&#x2f no window available&#x2f cant save local computer\n"
     ]
    }
   ],
   "source": [
    "print(text_clean['text'][0])\n",
    "print(text_clean['text'][9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words:  21701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['new platform suck unabl manag client look like fool client tri convert 2015 9 99 promot unabl access support noth me ',\n",
       " 'still mani glitch ',\n",
       " 'jjjjjjjjjjjjjjjjjjjjjjj ',\n",
       " 'work well ',\n",
       " 'slow difficult use challeng figur accomplish simplest task quickbook desktop far superior product qbo ridicul ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter=PorterStemmer()\n",
    "\n",
    "text_clean_stemmed = []\n",
    "for reviews in text_clean['text']:\n",
    "    stems = [porter.stem(word)+' ' for word in reviews.split()]\n",
    "    text_clean_stemmed.append(\"\".join(stems))\n",
    "\n",
    "print('Number of unique words: ',count_words(text_clean_stemmed))    \n",
    "text_clean_stemmed[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words:  26573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['new platform suck unable manage client look like fool client tried convert 2015 9 99 promotion unable access support nothing me ',\n",
       " 'still many glitch ',\n",
       " 'jjjjjjjjjjjjjjjjjjjjjjj ',\n",
       " 'work well ',\n",
       " 'slow difficult use challenging figure accomplish simplest task quickbooks desktop far superior product qbo ridiculous ']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer =WordNetLemmatizer()\n",
    "\n",
    "text_clean_lemmatized = []\n",
    "for reviews in text_clean['text']:\n",
    "    stems = [lemmatizer.lemmatize(word)+' ' for word in reviews.split()]\n",
    "    text_clean_lemmatized.append(\"\".join(stems))\n",
    "\n",
    "print('Number of unique words: ',count_words(text_clean_lemmatized))    \n",
    "text_clean_lemmatized[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model to predict Sentiment\n",
    "\n",
    "The following steps are used in creating Sentiment model:\n",
    "\n",
    "1. Count Vectorization\n",
    "2. TF-IDF Vectorization\n",
    "3. Split Training Data\n",
    "4. Build Logistic Regression Model\n",
    "5. Parameter Tuning\n",
    "6. Create final model\n",
    "7. Surmise sentiment words\n",
    "\n",
    "### Vectorize reviews using Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X:  (154429, 21701)\n",
      "First review: \n",
      "   (0, 10901)\t1\n",
      "  (0, 12966)\t1\n",
      "  (0, 18465)\t1\n",
      "  (0, 783)\t1\n",
      "  (0, 15188)\t1\n",
      "  (0, 657)\t1\n",
      "  (0, 228)\t1\n",
      "  (0, 4347)\t1\n",
      "  (0, 19536)\t1\n",
      "  (0, 7346)\t1\n",
      "  (0, 10351)\t1\n",
      "  (0, 10570)\t1\n",
      "  (0, 3600)\t1\n",
      "  (0, 10743)\t1\n",
      "  (0, 19744)\t1\n",
      "  (0, 18378)\t1\n",
      "  (0, 14560)\t1\n",
      "  (0, 12005)\t1\n",
      "Sample features: \n",
      " ['mdt', 'me', 'meal', 'mean', 'meani', 'meaning', 'meaningless', 'meant', 'meantim', 'meanwhil', 'measur', 'meat', 'meatier', 'meaur', 'mechan', 'med', 'meddl', 'media', 'mediamdevic', 'medic', 'medicar', 'medicor', 'mediev', 'medio', 'mediocor', 'mediocr', 'mediocrenreport', 'mediorcenshort', 'medium', 'mediumspeedbookswithquirkyidiosyncrasi', 'medley', 'medocr', 'medssi', 'meed', 'meer', 'mees', 'meet', 'meeting', 'meg', 'meh', 'meilleur', 'mejor', 'mejorando', 'meleni', 'melika', 'member', 'membership', 'meme', 'memeb', 'memo', 'memor', 'memori', 'memoris', 'memorize', 'memorized', 'men', 'menand', 'meni', 'menial', 'menlov', 'mennonit', 'meno', 'menori', 'mensuel', 'ment', 'mental', 'menth', 'mention', 'mentionné', 'mentor', 'menu', 'menudriven', 'menunno', 'menuntrud', 'menus', 'menusndoubl', 'meow', 'mer', 'mercado', 'merch', 'merchand', 'merchandis', 'merchandise', 'merchant', 'merci', 'merd', 'mere', 'merg', 'merger', 'meridian', 'merit', 'merri', 'mesh', 'mess', 'messag', 'message', 'messages', 'messaging', 'messay', 'messeng']\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "X = cv.fit_transform(text_clean_stemmed)\n",
    "\n",
    "print('Size of X: ',X.shape)\n",
    "print('First review: \\n',X[0])\n",
    "print('Sample features: \\n',cv.get_feature_names()[10900:11000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize reviews using TFIDF Vectorizer\n",
    "\n",
    "Let's define a few terms related to TF-IDF:\n",
    "\n",
    "**TF (Term Frequency)** :\n",
    "Denotes the contribution of the word to the document i.e. words relevant to the document should be frequent. \n",
    "\n",
    "            TF = (Number of times term t appears in a document)/(Number of terms in the document)\n",
    "\n",
    "**IDF (Inverse Document Frequency)** :\n",
    "If a word has appeared in all the documents, then probably that word is not relevant to a particular document. \n",
    "But, if it has appeared in a subset of documents then probably the word is of some relevance to the documents it is present in.\n",
    "\n",
    "           IDF = log(N/n), where, N is the number of documents and n is the number of documents a term t has appeared in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X:  (154429, 21701)\n",
      "First review: \n",
      "   (0, 12005)\t0.16997032066293502\n",
      "  (0, 14560)\t0.19819278336914592\n",
      "  (0, 18378)\t0.2079454023503958\n",
      "  (0, 19744)\t0.45511347221140813\n",
      "  (0, 10743)\t0.1773455019956885\n",
      "  (0, 3600)\t0.18686293619824967\n",
      "  (0, 10570)\t0.1767288901897543\n",
      "  (0, 10351)\t0.11350651207087983\n",
      "  (0, 7346)\t0.3333941432442282\n",
      "  (0, 19536)\t0.17373470348050826\n",
      "  (0, 4347)\t0.2403539351351772\n",
      "  (0, 228)\t0.29919209675070857\n",
      "  (0, 657)\t0.3100586062637267\n",
      "  (0, 15188)\t0.25960084137277506\n",
      "  (0, 783)\t0.11590455597314346\n",
      "  (0, 18465)\t0.13639195508149998\n",
      "  (0, 12966)\t0.2127511671866517\n",
      "  (0, 10901)\t0.20377482968442318\n",
      "Sample features: \n",
      " ['mdt', 'me', 'meal', 'mean', 'meani', 'meaning', 'meaningless', 'meant', 'meantim', 'meanwhil', 'measur', 'meat', 'meatier', 'meaur', 'mechan', 'med', 'meddl', 'media', 'mediamdevic', 'medic', 'medicar', 'medicor', 'mediev', 'medio', 'mediocor', 'mediocr', 'mediocrenreport', 'mediorcenshort', 'medium', 'mediumspeedbookswithquirkyidiosyncrasi', 'medley', 'medocr', 'medssi', 'meed', 'meer', 'mees', 'meet', 'meeting', 'meg', 'meh', 'meilleur', 'mejor', 'mejorando', 'meleni', 'melika', 'member', 'membership', 'meme', 'memeb', 'memo', 'memor', 'memori', 'memoris', 'memorize', 'memorized', 'men', 'menand', 'meni', 'menial', 'menlov', 'mennonit', 'meno', 'menori', 'mensuel', 'ment', 'mental', 'menth', 'mention', 'mentionné', 'mentor', 'menu', 'menudriven', 'menunno', 'menuntrud', 'menus', 'menusndoubl', 'meow', 'mer', 'mercado', 'merch', 'merchand', 'merchandis', 'merchandise', 'merchant', 'merci', 'merd', 'mere', 'merg', 'merger', 'meridian', 'merit', 'merri', 'mesh', 'mess', 'messag', 'message', 'messages', 'messaging', 'messay', 'messeng']\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer() #ngram_range=(1, 2))\n",
    "X = tfidf.fit_transform(text_clean_stemmed)\n",
    "\n",
    "print('Size of X: ',X.shape)\n",
    "print('First review: \\n',X[0])\n",
    "print('Sample features: \\n',tfidf.get_feature_names()[10900:11000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ふぇうぃｂ</th>\n",
       "      <td>12.254349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reqest</th>\n",
       "      <td>12.254349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>requirementsn</th>\n",
       "      <td>12.254349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impercept</th>\n",
       "      <td>12.254349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imperfectionsng</th>\n",
       "      <td>12.254349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>requikrements</th>\n",
       "      <td>12.254349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imping</th>\n",
       "      <td>12.254349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>implant</th>\n",
       "      <td>12.254349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>implel</th>\n",
       "      <td>12.254349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>requestng</th>\n",
       "      <td>12.254349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tfidf\n",
       "ふぇうぃｂ            12.254349\n",
       "reqest           12.254349\n",
       "requirementsn    12.254349\n",
       "impercept        12.254349\n",
       "imperfectionsng  12.254349\n",
       "requikrements    12.254349\n",
       "imping           12.254349\n",
       "implant          12.254349\n",
       "implel           12.254349\n",
       "requestng        12.254349"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_results = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "tfidf_results = pd.DataFrame(columns=['tfidf']).from_dict(\n",
    "                    dict(tfidf_results), orient='index')\n",
    "tfidf_results.columns = ['tfidf']\n",
    "tfidf_results.sort_values(by=['tfidf'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>2.329296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client</th>\n",
       "      <td>2.775242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easi</th>\n",
       "      <td>2.787817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account</th>\n",
       "      <td>3.002675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desktop</th>\n",
       "      <td>3.089163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>version</th>\n",
       "      <td>3.093304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>3.108334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onlin</th>\n",
       "      <td>3.176683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x27</th>\n",
       "      <td>3.331757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>3.371541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tfidf\n",
       "use      2.329296\n",
       "client   2.775242\n",
       "easi     2.787817\n",
       "account  3.002675\n",
       "desktop  3.089163\n",
       "version  3.093304\n",
       "amp      3.108334\n",
       "onlin    3.176683\n",
       "x27      3.331757\n",
       "like     3.371541"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_results.sort_values(by=['tfidf'], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data 75-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, ratings, train_size = 0.75, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training data for parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8143389970990468\n",
      "Accuracy for C=0.05: 0.8306741262605333\n",
      "Accuracy for C=0.25: 0.838168255283879\n",
      "Accuracy for C=0.5: 0.8395151263986739\n",
      "Accuracy for C=1: 0.839687802182622\n",
      "Accuracy for C=2: 0.8390316342036193\n",
      "Accuracy for C=4: 0.8373394115209283\n",
      "Accuracy for C=8: 0.83540544274071\n",
      "Accuracy for C=10: 0.8348183450752866\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_val, y_train2, y_val = train_test_split(\n",
    "    X_train, y_train, train_size = 0.75, random_state=1)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1, 2, 4, 8, 10]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train2, y_train2)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test model using best parameter on all of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8414059262329051\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=1)\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>-0.416035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>-0.749372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000</td>\n",
       "      <td>0.364080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000th</td>\n",
       "      <td>-0.129536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000x</td>\n",
       "      <td>-0.050742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01</td>\n",
       "      <td>-0.069853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0113</td>\n",
       "      <td>-0.192663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0151</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01nit</td>\n",
       "      <td>0.336213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Features  Coefficients\n",
       "0       00     -0.416035\n",
       "1      000     -0.749372\n",
       "2    00000      0.364080\n",
       "3     0001      0.000000\n",
       "4    000th     -0.129536\n",
       "5     000x     -0.050742\n",
       "6       01     -0.069853\n",
       "7     0113     -0.192663\n",
       "8     0151      0.000000\n",
       "9    01nit      0.336213"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "    \n",
    "features=pd.DataFrame(list(feature_to_coef.items()), columns=['Features','Coefficients'])\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most positive words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('love', 4.398575755498221)\n",
      "('awesom', 3.99392143120901)\n",
      "('great', 3.701669165398693)\n",
      "('excel', 3.591794023989809)\n",
      "('eas', 3.3076066438632425)\n",
      "('easi', 3.2675227640456077)\n",
      "('best', 2.9614427809927495)\n",
      "('amaz', 2.862395673535808)\n",
      "('10', 2.842353426389865)\n",
      "('wherev', 2.8218055495939196)\n",
      "('perfect', 2.6629086905679946)\n",
      "('tool', 2.6384798159933958)\n",
      "('save', 2.4900086328417306)\n",
      "('anywher', 2.472131836852879)\n",
      "('futur', 2.4520819477098956)\n"
     ]
    }
   ],
   "source": [
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:15]:\n",
    "    print (best_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most negative words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('poor', -5.772262104278763)\n",
      "('difficult', -5.751942704953135)\n",
      "('slow', -5.497332847986067)\n",
      "('terribl', -4.949237060697209)\n",
      "('clunki', -4.526206844451933)\n",
      "('imposs', -4.525519761910107)\n",
      "('hard', -4.45445059222422)\n",
      "('lack', -4.425420643329863)\n",
      "('worst', -4.313577315831901)\n",
      "('don', -4.23081036078803)\n",
      "('doesn', -4.220828352890409)\n",
      "('cannot', -4.177126602614009)\n",
      "('horribl', -4.141687054031067)\n",
      "('desktop', -4.10451832536255)\n",
      "('cumbersom', -3.9665690354344254)\n"
     ]
    }
   ],
   "source": [
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:15]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
